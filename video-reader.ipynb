{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing and Transmitting Data Using Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Libraries Used for This Project\n",
    "1. <u>**OpenCV**</u> - is a computer vision and machine learning library that provides a wide range of tools and functions for image and video processing.\n",
    "2. <u>**Numpy**</u> - is a Python library that provides powerful tools for working with multi-dimensional arrays and matrices, enabling efficient data manipulation.\n",
    "3. <u>**Time**</u> - is a library providing tools for time manipulation, such as time measurement, program delay, and more.\n",
    "4. <u>**OS**</u> - is a library providing various methods for interacting with the operating system.\n",
    "5. <u>**Requests**</u> - is a Python library for making HTTP requests, allowing easy communication with web servers and APIs.\n",
    "6. <u>**JSON**</u> - is a built-in Python library for encoding and decoding JSON data, commonly used for exchanging data between a server and a web application.\n",
    "7. <u>**Datetime**</u> - is a built-in Python library providing classes for manipulating dates and times, offering functionalities such as formatting dates, calculating time differences, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for Sending Data\n",
    "1. It retrieves the endpoint from environment variables and gets the current time in UTC format.\n",
    "2. Then, it prepares a payload containing the temperature value and current time.\n",
    "3. It sets the headers to indicate JSON content.\n",
    "4. Finally, it sends a POST request to the endpoint with the payload as JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_value(value):\n",
    "    endpoint = os.getenv(\"ENDPOINT\")\n",
    "    current_time = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    payload = {\n",
    "        \"Temperature\": value,\n",
    "        \"Date\": current_time\n",
    "        }\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=json.dumps(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper method for obtaining the diameter and position of the circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_circles(circles, b):\n",
    "    avg_x = 0\n",
    "    avg_y = 0\n",
    "    avg_r = 0\n",
    "    for i in range(b):\n",
    "        avg_x += circles[0][i][0]\n",
    "        avg_y += circles[0][i][1]\n",
    "        avg_r += circles[0][i][2]\n",
    "    avg_x = int(avg_x / (b))\n",
    "    avg_y = int(avg_y / (b))\n",
    "    avg_r = int(avg_r / (b))\n",
    "\n",
    "    return avg_x, avg_y, avg_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for Obtaining the Distance Between Two Points in Two-Dimensional Space\n",
    "- Utilizing the Pythagorean theorem in a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_2_pts(x1, y1, x2, y2):\n",
    "    return np.sqrt((x2 - x1)**2 + (y2 - y1)**2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection and Calibration of Captured Circles\n",
    "1. Loads the specified frame.\n",
    "2. Converts the image to grayscale.\n",
    "3. Detects circular objects in the image using the HoughCircles method from the OpenCV library.\n",
    "4. Computes the average values for the detected circles.\n",
    "5. Draws circles and calibration markers on the image.\n",
    "6. Allows the user to input desired values through visual representation.\n",
    "7. Returns the minimum and maximum angle values, minimum and maximum values, units, and coordinates of the center and radius of the detected circle for further use in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_gauge(folder_path, filename):\n",
    "\timg = cv.imread(f\"{folder_path}/{filename}.jpg\")\n",
    "\theight, width = img.shape[:2]\n",
    "\tgray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "\tcircles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, 1, 20, np.array([]), 100, 50, int(height * 0.35), int(height * 0.48))\n",
    "\ta, b, c = circles.shape\n",
    "\tx,y,r = avg_circles(circles, b)\n",
    "\n",
    "\tcv.circle(img, (x, y), r, (0, 0, 255), 3, cv.LINE_AA)  \n",
    "\tcv.circle(img, (x, y), 2, (0, 255, 0), 3, cv.LINE_AA) \n",
    "\n",
    "\tseparation = 10.0\n",
    "\tinterval = int(360 / separation)\n",
    "\tp1 = np.zeros((interval,2))  \n",
    "\tp2 = np.zeros((interval,2))\n",
    "\tp_text = np.zeros((interval,2))\n",
    "\n",
    "\tfor i in range(0,interval):\n",
    "\t\tfor j in range(0,2):\n",
    "\t\t\tif (j % 2 == 0):\n",
    "\t\t\t\tp1[i][j] = x + 0.9 * r * np.cos(separation * i * 3.14 / 180)\n",
    "\t\t\telse:\n",
    "\t\t\t\tp1[i][j] = y + 0.9 * r * np.sin(separation * i * 3.14 / 180)\n",
    "\n",
    "\ttext_offset_x = 10\n",
    "\ttext_offset_y = 5\n",
    "\n",
    "\tfor i in range(0, interval):\n",
    "\t\tfor j in range(0, 2):\n",
    "\t\t\tif (j % 2 == 0):\n",
    "\t\t\t\tp2[i][j] = x + r * np.cos(separation * i * 3.14 / 180)\n",
    "\t\t\t\tp_text[i][j] = x - text_offset_x + 1.2 * r * np.cos((separation) * (i + 9) * 3.14 / 180) \n",
    "\t\t\telse:\n",
    "\t\t\t\tp2[i][j] = y + r * np.sin(separation * i * 3.14 / 180)\n",
    "\t\t\t\tp_text[i][j] = y + text_offset_y + 1.2 * r * np.sin((separation) * (i + 9) * 3.14 / 180)\n",
    "\n",
    "\tfor i in range(0,interval):\n",
    "\t\tcv.line(img, (int(p1[i][0]), int(p1[i][1])), (int(p2[i][0]), int(p2[i][1])),(0, 255, 0), 2)\n",
    "\t\tcv.putText(img, '%s' %(int(i * separation)), (int(p_text[i][0]), int(p_text[i][1])), cv.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0), 1, cv.LINE_AA)\n",
    "\n",
    "\tcv.imwrite(f\"{folder_path}/{filename}-calibration.jpg\", img)\n",
    "\n",
    "\tprint (f\"Created: {filename}-calibration.jpg\")\n",
    "\tmin_angle = input('Min angle (lowest possible angle of dial) - in degrees: ')\n",
    "\tmax_angle = input('Max angle (highest possible angle) - in degrees: ') \n",
    "\tmin_value = input('Min value: ') \n",
    "\tmax_value = input('Max value: ') \n",
    "\tunits = input('Enter units: ')\n",
    "\n",
    "\treturn min_angle, max_angle, min_value, max_value, units, x, y, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining and Printing Values from a Calibrated Image\n",
    "1. Converts the image to grayscale using the cv.cvtColor() method.\n",
    "2. Applies thresholding to the grayscale image using the cv.threshold() method.\n",
    "3. Detects lines in the image using the HoughLinesP method from the OpenCV library.\n",
    "4. Selects only those lines that are close to the center of the detected circle and have the correct orientation.\n",
    "5. Determines the angle at which the pointer is displayed and converts it to a value within the defined range.\n",
    "6. Returns the current value of the device based on the position of the pointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_value(img, min_angle, max_angle, min_value, max_value, x, y, r, folder_path,filename):\n",
    "\tgray2 = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\tthresh = 175\n",
    "\tmaxValue = 255\n",
    "\n",
    "\tth, dst2 = cv.threshold(gray2, thresh, maxValue, cv.THRESH_BINARY_INV);\n",
    "\n",
    "\tminLineLength = 10\n",
    "\tmaxLineGap = 0\n",
    "\tlines = cv.HoughLinesP(image=dst2, rho=3, theta=np.pi / 180, threshold=100,minLineLength=minLineLength, maxLineGap=0)\n",
    "\n",
    "\tfinal_line_list = []\n",
    "\n",
    "\tdiff1LowerBound = 0.15 \n",
    "\tdiff1UpperBound = 0.25\n",
    "\tdiff2LowerBound = 0.5 \n",
    "\tdiff2UpperBound = 1.0\n",
    "\tfor i in range(0, len(lines)):\n",
    "\t\tfor x1, y1, x2, y2 in lines[i]:\n",
    "\t\t\tdiff1 = dist_2_pts(x, y, x1, y1) \n",
    "\t\t\tdiff2 = dist_2_pts(x, y, x2, y2) \n",
    "\t\t\tif (diff1 > diff2):\n",
    "\t\t\t\ttemp = diff1\n",
    "\t\t\t\tdiff1 = diff2\n",
    "\t\t\t\tdiff2 = temp\n",
    "\t\t\tif (((diff1<diff1UpperBound * r) and (diff1 > diff1LowerBound * r) and (diff2 < diff2UpperBound * r)) and (diff2 > diff2LowerBound * r)):\n",
    "\t\t\t\tline_length = dist_2_pts(x1, y1, x2, y2)\n",
    "\t\t\t\tfinal_line_list.append([x1, y1, x2, y2])\n",
    "\n",
    "\tif final_line_list:\n",
    "\t\tx1 = final_line_list[0][0]\n",
    "\t\ty1 = final_line_list[0][1]\n",
    "\t\tx2 = final_line_list[0][2]\n",
    "\t\ty2 = final_line_list[0][3]\n",
    "\t\tcv.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\telse:\n",
    "\t\tprint(\"None\")\n",
    "\n",
    "\tcv.imwrite(f\"{folder_path}/{filename}-needle.jpg\", img)\n",
    "\n",
    "\tdist_pt_0 = dist_2_pts(x, y, x1, y1)\n",
    "\tdist_pt_1 = dist_2_pts(x, y, x2, y2)\n",
    "\tif (dist_pt_0 > dist_pt_1):\n",
    "\t\tx_angle = x1 - x\n",
    "\t\ty_angle = y - y1\n",
    "\telse:\n",
    "\t\tx_angle = x2 - x\n",
    "\t\ty_angle = y - y2\n",
    "\n",
    "\tres = np.arctan(np.divide(float(y_angle), float(x_angle)))\n",
    "\n",
    "\tres = np.rad2deg(res)\n",
    "\tif x_angle > 0 and y_angle > 0:  # quadrant I\n",
    "\t\tfinal_angle = 270 - res\n",
    "\tif x_angle < 0 and y_angle > 0:  # quadrant II\n",
    "\t\tfinal_angle = 90 - res\n",
    "\tif x_angle < 0 and y_angle < 0:  # quadrant III\n",
    "\t\tfinal_angle = 90 - res\n",
    "\tif x_angle > 0 and y_angle < 0:  # quadrant IV\n",
    "\t\tfinal_angle = 270 - res\n",
    "\n",
    "\told_min = float(min_angle)\n",
    "\told_max = float(max_angle)\n",
    "\n",
    "\tnew_min = float(min_value)\n",
    "\tnew_max = float(max_value)\n",
    "\n",
    "\told_value = final_angle\n",
    "\n",
    "\told_range = (old_max - old_min)\n",
    "\tnew_range = (new_max - new_min)\n",
    "\tnew_value = (((old_value - old_min) * new_range) / old_range) + new_min\n",
    "\n",
    "\treturn new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method \n",
    "1. At the beginning, it opens a video file using cv.VideoCapture, which allows access to individual frames in the video.\n",
    "2. It tries to create a directory named \"Video\" if it does not exist, so that it can save output frames.\n",
    "3. Then it calibrates the gauge using the calibrate_gauge function, which obtains important parameters for measurement.\n",
    "4. In an infinite loop, it reads individual frames from the video.\n",
    "5. For each frame, it calls the get_current_value function, which determines the current value on the gauge based on calibration and the position of the pointer in the frame.\n",
    "6. It prints the current value and sends it to desired location(I used PowerBI api).\n",
    "7. Finally, it removes temporary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    capture = cv.VideoCapture(\"gauge_sim.mp4\")\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(\"Video\"):\n",
    "            os.makedirs(\"Video\")\n",
    "    except:\n",
    "        print(\"ERROR creating directory\")\n",
    "\n",
    "    need_config = True\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()\n",
    "\n",
    "        name = \"Video/frame.jpg\"\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        cv.imwrite(name, frame)\n",
    "\n",
    "        if need_config:\n",
    "            min_angle, max_angle, min_value, max_value, units, x, y, r = calibrate_gauge(\"Video\", \"frame\")\n",
    "            need_config = False\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        img = cv.imread(name)\n",
    "        value = get_current_value(img, min_angle, max_angle, min_value, max_value, x, y, r, \"Video\", \"frame\")\n",
    "        print (\"Current reading: %s %s\" %((\"%.2f\" % value), units))\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        send_value(value)\n",
    "\n",
    "        os.remove(name)\n",
    "        os.remove(\"Video/frame-needle.jpg\")\n",
    "\n",
    "        if cv.waitKey(20) == ord('d'):\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
